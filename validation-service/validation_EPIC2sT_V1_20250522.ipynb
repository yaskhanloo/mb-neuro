{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automozed EPIC validation process against secuTrial data entries\n",
    "\n",
    "created by: Yasaman Safarkhanlo on 2024.10.07\n",
    "\n",
    "last modified: file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import chardet\n",
    "import logging\n",
    "import re\n",
    "import io\n",
    "from typing import Dict, Any, Optional, Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    \"\"\"Configure logging for the application, works both locally and in Docker\"\"\"\n",
    "    # Detect environment: if running in Docker, use /app/data/logs; else, use ./logs\n",
    "    base_dir = os.getenv('BASE_DIR', '.')  # Docker should set BASE_DIR=/app/data\n",
    "    log_dir = Path(base_dir) / \"logs\"\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = log_dir / f\"validation_service_{timestamp}.log\"\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return logging.getLogger('epic-validation')\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_modify_secuTrial_export(df):\n",
    "    \"\"\"\n",
    "    Process secuTrial export dataframe by removing metadata rows and setting proper headers.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return (df.iloc[6:]\n",
    "                 .pipe(lambda x: x.set_axis(x.iloc[0], axis=1))\n",
    "                 .iloc[1:]\n",
    "                 .reset_index(drop=True)\n",
    "                 .dropna(how='all'))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing secuTrial export: {e}\")\n",
    "        return df\n",
    "\n",
    "def safe_read_file(file_path, custom_reader=None):\n",
    "    \"\"\"\n",
    "    Safely reads a file (Excel or CSV), with an option for a custom reader function.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    file_extension = file_path.suffix.lower()\n",
    "\n",
    "    try:\n",
    "        if file_extension in [\".xlsx\", \".xls\"]:\n",
    "            df = pd.read_excel(file_path, engine='openpyxl' if file_extension == \".xlsx\" else 'xlrd')\n",
    "        elif file_extension == \".csv\":\n",
    "            encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "            df = None\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, encoding=encoding)\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            if df is None:\n",
    "                raise ValueError(\"Could not read CSV with any encoding\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "        \n",
    "        result = custom_reader(df) if custom_reader else df\n",
    "\n",
    "        if result is None or result.empty:\n",
    "            logger.warning(f\"{file_path.name} is empty after processing.\")\n",
    "            return None\n",
    "\n",
    "        return result\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file at {file_path}: {e}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 10:16:27,836 - epic-validation - INFO - Latest secuTrial export found: /Users/yaskhanloo/Developer/bern-storke-center/sT-files/export-20250520\n",
      "2025-05-23 10:16:27,841 - epic-validation - INFO - Latest EPIC export found: /Users/yaskhanloo/Developer/bern-storke-center/EPIC-files/export-20250516\n",
      "/Users/yaskhanloo/Library/Python/3.9/lib/python/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/yaskhanloo/Library/Python/3.9/lib/python/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "2025-05-23 10:16:43,311 - epic-validation - INFO - Data loaded successfully: secuTrial=(1803, 174), REVASC=(4979, 256), EPIC=(2543, 18)\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(\"/Users/yaskhanloo/Developer/bern-storke-center\")\n",
    "\n",
    "# Dynamically find the latest export folders\n",
    "latest_sT_export = max((base_dir / \"sT-files\").glob(\"export-*\"), key=lambda x: x.stat().st_mtime, default=None)\n",
    "latest_EPIC_export = max((base_dir / \"EPIC-files\").glob(\"export-*\"), key=lambda x: x.stat().st_mtime, default=None)\n",
    "\n",
    "if latest_sT_export:\n",
    "    secuTrial_base_dir = latest_sT_export\n",
    "    REVASC_base_dir = secuTrial_base_dir / \"REVASC\"\n",
    "    logger.info(f\"Latest secuTrial export found: {secuTrial_base_dir}\")\n",
    "else:\n",
    "    logger.error(\"No valid secuTrial export directory found.\")\n",
    "    raise FileNotFoundError(\"No valid secuTrial export directory found.\")\n",
    "\n",
    "if latest_EPIC_export:\n",
    "    epic_base_dir = latest_EPIC_export\n",
    "    logger.info(f\"Latest EPIC export found: {epic_base_dir}\")\n",
    "else:\n",
    "    logger.error(\"No valid EPIC export directory found.\")\n",
    "    raise FileNotFoundError(\"No valid EPIC export directory found.\")\n",
    "\n",
    "# Define file paths\n",
    "file_path_secuTrial = secuTrial_base_dir / 'SSR_cases_of_2024.xlsx'\n",
    "file_path_REVASC = REVASC_base_dir / 'report_SSR01_20250218-105747.xlsx'\n",
    "file_path_EPIC = epic_base_dir / 'encounters.xlsx'\n",
    "\n",
    "# Read files\n",
    "df_secuTrial = safe_read_file(file_path_secuTrial, custom_reader=read_and_modify_secuTrial_export)\n",
    "df_REVASC = safe_read_file(file_path_REVASC, custom_reader=read_and_modify_secuTrial_export)\n",
    "df_EPIC = safe_read_file(file_path_EPIC)\n",
    "\n",
    "# Log data frame sizes\n",
    "if df_secuTrial is not None and df_EPIC is not None and df_REVASC is not None:\n",
    "    logger.info(f\"Data loaded successfully: secuTrial={df_secuTrial.shape}, REVASC={df_REVASC.shape}, EPIC={df_EPIC.shape}\")\n",
    "else:\n",
    "    logger.warning(\"One or more dataframes failed to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all EPIC files into one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_single_epic_file(file_path, merge_column, merged_df, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Merge a single EPIC file into the main DataFrame with optional column prefixing.\n",
    "    \"\"\"\n",
    "    df = safe_read_file(file_path)\n",
    "    if df is None:\n",
    "        logger.warning(f\"Failed to read {file_path.name}\")\n",
    "        return merged_df\n",
    "\n",
    "    if merge_column not in df.columns:\n",
    "        logger.warning(f\"Merge column '{merge_column}' not found in {file_path.name}\")\n",
    "        return merged_df\n",
    "\n",
    "    # Add prefix to all columns except the merge column\n",
    "    if prefix:\n",
    "        df = df.rename(columns={col: f\"{prefix}{col}\" for col in df.columns if col != merge_column})\n",
    "\n",
    "    # Merge logic\n",
    "    if merged_df.empty:\n",
    "        result_df = df.copy()\n",
    "        logger.info(f\"Using {file_path.name} as base: shape={result_df.shape}\")\n",
    "    else:\n",
    "        result_df = merged_df.merge(df, on=merge_column, how=\"outer\")\n",
    "        logger.info(f\"Merged {file_path.name}: shape={df.shape} → total={result_df.shape}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def merge_all_epic_files(directory, merge_column):\n",
    "    \"\"\"\n",
    "    Merges all EPIC files in a directory based on a specific column, in a defined order.\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    if not directory.exists():\n",
    "        logger.error(f\"Directory not found: {directory}\")\n",
    "        raise FileNotFoundError(f\"{directory} does not exist.\")\n",
    "\n",
    "    file_patterns = [\"*.xlsx\", \"*.xls\", \"*.csv\"]\n",
    "    all_files = [f for pattern in file_patterns for f in directory.glob(pattern)]\n",
    "    logger.info(f\"Found {len(all_files)} data files in {directory.name}\")\n",
    "\n",
    "    file_order = ['enc', 'flow', 'imag', 'img', 'lab', 'med', 'mon']\n",
    "\n",
    "    def file_priority(file_path):\n",
    "        name = file_path.stem.lower()\n",
    "        for i, keyword in enumerate(file_order):\n",
    "            if keyword in name:\n",
    "                return i\n",
    "        return len(file_order)\n",
    "\n",
    "    def get_prefix(filename):\n",
    "        name = filename.lower()\n",
    "        if 'enc' in name: return 'enct.'\n",
    "        if 'flow' in name: return 'flow.'\n",
    "        if 'imag' in name or 'img' in name: return 'img.'\n",
    "        if 'lab' in name: return 'lab.'\n",
    "        if 'med' in name: return 'med.'\n",
    "        if 'mon' in name: return 'mon.'\n",
    "        return \"\"\n",
    "\n",
    "    sorted_files = sorted(all_files, key=file_priority)\n",
    "\n",
    "    merged_df = pd.DataFrame()\n",
    "    for file_path in sorted_files:\n",
    "        prefix = get_prefix(file_path.stem)\n",
    "        merged_df = merge_single_epic_file(file_path, merge_column, merged_df, prefix)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 10:16:43,334 - epic-validation - INFO - Listing files in EPIC export directory: /Users/yaskhanloo/Developer/bern-storke-center/EPIC-files/export-20250516\n",
      "2025-05-23 10:16:43,343 - epic-validation - INFO - Found 6 data files in export-20250516\n",
      "2025-05-23 10:16:43,615 - epic-validation - INFO - Using encounters.xlsx as base: shape=(2543, 18)\n",
      "2025-05-23 10:16:43,992 - epic-validation - INFO - Merged flowsheet.xlsx: shape=(2543, 31) → total=(2543, 48)\n",
      "2025-05-23 10:16:44,183 - epic-validation - INFO - Merged imaging.xlsx: shape=(2543, 16) → total=(2543, 63)\n",
      "2025-05-23 10:16:44,368 - epic-validation - INFO - Merged lab.xlsx: shape=(2543, 14) → total=(2543, 76)\n",
      "2025-05-23 10:16:44,651 - epic-validation - INFO - Merged medication.xlsx: shape=(2543, 23) → total=(2543, 98)\n",
      "2025-05-23 10:16:44,877 - epic-validation - INFO - Merged monitor.xlsx: shape=(2543, 18) → total=(2543, 115)\n",
      "2025-05-23 10:16:44,878 - epic-validation - INFO - Final merged DataFrame shape: (2543, 115)\n",
      "2025-05-23 10:16:44,932 - epic-validation - INFO - Merged data saved to: /Users/yaskhanloo/Developer/bern-storke-center/EPIC-files/merged_epic_files/merged_epic_data.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # List all files in the EPIC export directory\n",
    "    logger.info(f\"Listing files in EPIC export directory: {epic_base_dir}\")\n",
    "    all_files = list(Path(epic_base_dir).glob(\"*\"))\n",
    "    for file in all_files:\n",
    "        logger.debug(f\"  - {file.name}\")\n",
    "    \n",
    "    # Merge all EPIC files\n",
    "    df_EPIC_all = merge_all_epic_files(epic_base_dir, merge_column=\"PAT_ENC_CSN_ID\")\n",
    "    \n",
    "    if not df_EPIC_all.empty:\n",
    "        logger.info(f\"Final merged DataFrame shape: {df_EPIC_all.shape}\")\n",
    "\n",
    "        # Save the merged dataframe\n",
    "        output_path = Path(base_dir) / \"EPIC-files/merged_epic_files/merged_epic_data.csv\"\n",
    "        df_EPIC_all.to_csv(output_path, index=False)\n",
    "        logger.info(f\"Merged data saved to: {output_path}\")\n",
    "    else:\n",
    "        logger.warning(\"Merged DataFrame is empty. Nothing saved.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error: Directory not found - {e}\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An unexpected error occurred during merging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVASC merge with sT - single year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unnamed columns in df_secuTrial\n",
    "unnamed_columns_secuTrial = [col for col in df_secuTrial.columns if not isinstance(col, str) or not col or col.startswith('Unnamed')]\n",
    "if unnamed_columns_secuTrial:\n",
    "    print(f'Unnamed columns in df_secuTrial: {unnamed_columns_secuTrial}')\n",
    "else:\n",
    "    print('No unnamed columns found in df_secuTrial.')\n",
    "\n",
    "# Check for unnamed columns in df_REVASC\n",
    "unnamed_columns_REVASC = [col for col in df_REVASC.columns if not isinstance(col, str) or not col or col.startswith('Unnamed')]\n",
    "if unnamed_columns_REVASC:\n",
    "    print(f'Unnamed columns in df_REVASC: {unnamed_columns_REVASC}')\n",
    "else:\n",
    "    print('No unnamed columns found in df_REVASC.')\n",
    "\n",
    "# Merge df_REVASC into df_secuTrial based on Case ID, adding suffix to shared columns\n",
    "df_secuTrial_w_REVAS = df_secuTrial.merge(\n",
    "    df_REVASC,\n",
    "    how='left',\n",
    "    left_on='Case ID',\n",
    "    right_on='CaseID',\n",
    "    suffixes=('', '.revas')  # No suffix for df_secuTrial, '.revas' for df_REVASC\n",
    ")\n",
    "\n",
    "df_secuTrial_w_REVAS.drop(columns=['CaseID'], inplace=True, errors='ignore')\n",
    "df_secuTrial_w_REVAS.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'df_secuTrial_w_REVAS size: {df_secuTrial_w_REVAS.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add FID and SSR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EPIC_all['FID'] = df_EPIC_all['img.FID'].fillna(0).astype(int)\n",
    "df_EPIC_all.insert(0, 'FID', df_EPIC_all.pop('FID'))\n",
    "\n",
    "df_secuTrial_w_REVAS['SSR'] = df_secuTrial_w_REVAS['Case ID'].str.extract(r'(\\d+)$').astype(int)\n",
    "df_secuTrial_w_REVAS.insert(1, 'SSR', df_secuTrial_w_REVAS.pop('SSR'))\n",
    "df_secuTrial_w_REVAS = df_secuTrial_w_REVAS.drop(columns=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_log = pd.read_excel(base_dir / 'EPIC2sT-pipeline/Identification_log_SSR_2024_ohne PW.xlsx')\n",
    "\n",
    "# Set the first row as column names and drop it from the data\n",
    "id_log.columns = id_log.iloc[0]\n",
    "id_log = id_log.iloc[1:].reset_index(drop=True)  # Reset index for clarity\n",
    "\n",
    "# Rename columns for consistency\n",
    "id_log.rename(columns={'Fall-Nr.(FID)': 'FID', 'SSR Identification SSR-INS-000....': 'SSR'}, inplace=True)\n",
    "\n",
    "# Merge with df_EPIC_all on 'FID' and reorder columns\n",
    "df_EPIC_all = df_EPIC_all.merge(id_log[['FID', 'SSR']], on='FID', how='left')\n",
    "df_EPIC_all.insert(1, 'SSR', df_EPIC_all.pop('SSR'))  # Move 'SSR' to the second column\n",
    "\n",
    "# Merge with df_secuTrial_w_REVAS on 'SSR' and reorder columns\n",
    "df_secuTrial_w_REVAS = df_secuTrial_w_REVAS.merge(id_log[['SSR', 'FID']], on='SSR', how='left')\n",
    "df_secuTrial_w_REVAS.insert(0, 'FID', df_secuTrial_w_REVAS.pop('FID'))  # Move 'FID' to the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common column names\n",
    "common_columns = df_secuTrial_w_REVAS.columns.intersection(df_EPIC_all.columns)\n",
    "\n",
    "print(common_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common values in 'FID' and 'SSR'\n",
    "common_values = df_secuTrial_w_REVAS[['FID', 'SSR']].merge(df_EPIC_all[['FID', 'SSR']], on=['FID', 'SSR'], how='inner')\n",
    "\n",
    "# Filter both DataFrames to keep only matching rows\n",
    "df_sT_common = df_secuTrial_w_REVAS.merge(common_values, on=['FID', 'SSR'], how='inner')\n",
    "df_ep_common = df_EPIC_all.merge(common_values, on=['FID', 'SSR'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sT_common.shape, df_ep_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = base_dir / 'EPIC-export-validation/validation-files'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_path = output_dir / \"merged_lists.xlsx\"\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    df_sT_common.to_excel(writer, sheet_name=\"secuTrial_list\", index=False)\n",
    "    df_ep_common.to_excel(writer, sheet_name=\"EPIC_list\", index=False)\n",
    "\n",
    "print(f\"Excel file saved as {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows that exist only in df1\n",
    "df_sT_only = df_secuTrial_w_REVAS.merge(df_EPIC_all[['FID', 'SSR']], on=['FID', 'SSR'], how='left', indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "\n",
    "# Find rows that exist only in df2\n",
    "df_ep_only = df_EPIC_all.merge(df_secuTrial_w_REVAS[['FID', 'SSR']], on=['FID', 'SSR'], how='left', indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sT_only.shape, df_ep_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the common columns in df1_only and df2_only\n",
    "df_sT_only_common_cols = df_sT_only[['FID', 'SSR', 'Last name', 'First name', 'DOB', 'Arrival at hospital']]\n",
    "df_ep_only_common_cols = df_ep_only[['FID', 'SSR','enct.name_last', 'enct.name_first', 'enct.birth_date', 'enct.arrival_date']]\n",
    "\n",
    "# Save to an Excel file\n",
    "# Define output directory and ensure it exists\n",
    "output_dir = base_dir / 'EPIC-export-validation/validation-files'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_path = output_dir / \"missing_patients_2024.xlsx\"\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    df_sT_only_common_cols.to_excel(writer, sheet_name=\"secuTrial_list\", index=False)\n",
    "    df_ep_only_common_cols.to_excel(writer, sheet_name=\"EPIC_list\", index=False)\n",
    "\n",
    "print(f\"Excel file saved as {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find the missing patients from EPIC and sT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column mappings\n",
    "df_sT_column_mapping = {\n",
    "    \"First name\": \"first_name\",\n",
    "    \"Last name\": \"last_name\",\n",
    "    \"DOB\": \"birth_date\",\n",
    "    \"Arrival at hospital\": \"arrival_date\"\n",
    "}\n",
    "\n",
    "df_ep_column_mapping = {\n",
    "    \"enct.name_first\": \"first_name\",\n",
    "    \"enct.name_last\": \"last_name\",\n",
    "    \"enct.birth_date\": \"birth_date\",\n",
    "    \"enct.arrival_date\": \"arrival_date\"\n",
    "}\n",
    "\n",
    "# Rename columns in both DataFrames to unify them\n",
    "df1_renamed = df_sT_only.rename(columns=df_sT_column_mapping)\n",
    "df2_renamed = df_ep_only.rename(columns=df_ep_column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_renamed['birth_date'] = pd.to_datetime(df1_renamed['birth_date'], errors='coerce').dt.date\n",
    "df2_renamed['birth_date'] = pd.to_datetime(df2_renamed['birth_date'], errors='coerce').dt.date\n",
    "df1_renamed['arrival_date'] = pd.to_datetime(df1_renamed['arrival_date'], errors='coerce').dt.date\n",
    "df2_renamed['arrival_date'] = pd.to_datetime(df2_renamed['arrival_date'], errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure columns exist before checking data types\n",
    "common_columns = [\"first_name\", \"last_name\", \"birth_date\"]\n",
    "\n",
    "# Function to check and match data types between two DataFrames\n",
    "def match_column_dtypes(df1, df2, columns):\n",
    "    for col in columns:\n",
    "        if col in df1.columns and col in df2.columns:\n",
    "            if df1[col].dtype != df2[col].dtype:\n",
    "                # Convert to a common type (string for names, datetime for dates)\n",
    "                if df1[col].dtype == \"object\" or df2[col].dtype == \"object\":\n",
    "                    df1[col] = df1[col].astype(str)\n",
    "                    df2[col] = df2[col].astype(str)\n",
    "                elif \"datetime\" in str(df1[col].dtype) or \"datetime\" in str(df2[col].dtype):\n",
    "                    df1[col] = pd.to_datetime(df1[col], errors='coerce')\n",
    "                    df2[col] = pd.to_datetime(df2[col], errors='coerce')\n",
    "\n",
    "# Match data types\n",
    "match_column_dtypes(df1_renamed, df2_renamed, common_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common rows based on unified columns\n",
    "df_common_patients = df1_renamed.merge(df2_renamed, on=common_columns, how=\"inner\", suffixes=('_sT', '_ep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common_patients[['SSR_sT', 'FID_sT', 'FID_ep', 'arrival_date_sT', 'arrival_date_ep'] + common_columns].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected columns to save\n",
    "selected_columns = ['SSR_sT', 'FID_sT', 'FID_ep', 'arrival_date_sT', 'arrival_date_ep'] + common_columns\n",
    "\n",
    "# Ensure df_common_patients exists and contains the required columns\n",
    "try:\n",
    "    # Select first 40 rows from the specified columns\n",
    "    df_to_save = df_common_patients[selected_columns].head(40)\n",
    "\n",
    "    # Define file path\n",
    "    file_path = output_dir / \"missing_patients_but exist.xlsx\"\n",
    "\n",
    "    # Save to Excel file\n",
    "    df_to_save.to_excel(file_path, index=False)\n",
    "\n",
    "    # Provide the download link\n",
    "    file_path\n",
    "\n",
    "except NameError:\n",
    "    print(\"Error: 'df_common_patients' is not defined. Please reload or redefine it.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing columns in 'df_common_patients': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read map file\n",
    "map_dir = base_dir / 'EPIC2sT-pipeline'\n",
    "map_file_name = 'map_epic2sT_code_V2_20250224.xlsx'\n",
    "\n",
    "map_file_path = map_dir / map_file_name\n",
    "\n",
    "# Load the column mapping Excel file\n",
    "df_mapping = pd.read_excel(map_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_mapping_dict, ep_type_conversion, ep_category_mappings, ep_datetime_formats = {}, {}, {}, {}\n",
    "sT_mapping_dict, sT_type_conversion, sT_category_mappings, sT_datetime_formats = {}, {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(x):\n",
    "    if pd.isna(x) or str(x).strip().lower() in [\"\", \"null\", \"nan\", \"<na>\", \"nat\"]:\n",
    "        return np.nan\n",
    "    return x\n",
    "\n",
    "def convert_to_bool(x):\n",
    "    if pd.isna(x) or str(x).strip().lower() in [\"\", \"null\", \"nan\", \"<na>\", \"nat\"]:\n",
    "        return np.nan\n",
    "    return str(x).strip().lower() in [\"true\", \"yes\", \"1\"]\n",
    "\n",
    "def safe_datetime_conversion(s, col_name=None, source=None):\n",
    "    \"\"\"\n",
    "    Converts a column to datetime safely, using specific formats if available.\n",
    "    \"\"\"\n",
    "    # Apply specific formatting if applicable\n",
    "    if source == \"sT\" and col_name in sT_datetime_formats:\n",
    "        date_format = sT_datetime_formats[col_name]\n",
    "    elif source == \"ep\" and col_name in ep_datetime_formats:\n",
    "        date_format = ep_datetime_formats[col_name]\n",
    "    else:\n",
    "        date_format = None  # Use default parsing\n",
    "    \n",
    "    return pd.to_datetime(s.astype(str).str.strip(), format=date_format, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_numeric_conversion(series, dtype):\n",
    "    \"\"\"Convert series to numeric type safely.\"\"\"\n",
    "    series = series.map(handle_missing_values)\n",
    "    if dtype == \"int\":\n",
    "        return pd.to_numeric(series, errors=\"coerce\").astype(\"Int64\")\n",
    "    elif dtype == \"float\":\n",
    "        return pd.to_numeric(series, errors=\"coerce\").astype(float)\n",
    "    elif dtype == \"float-2\":\n",
    "        return pd.to_numeric(series, errors=\"coerce\").round(2)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sT data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_secutrial_mapping(row):\n",
    "    source_file = row[\"sT_exportFileName\"]\n",
    "    var_name = row[\"sT_varColumnName\"]\n",
    "    var_dtype = row[\"sT_varType\"]\n",
    "    var_map = row.get(\"sT_varMap\", None)  \n",
    "\n",
    "    # Determine column suffix\n",
    "    suffix = \".revas\" if isinstance(source_file, str) and \"REVASC\" in source_file else \"\"\n",
    "\n",
    "    # Ensure var_name is valid before concatenation\n",
    "    if pd.notna(var_name):\n",
    "        full_var_name = str(var_name).strip() + suffix\n",
    "        sT_mapping_dict[full_var_name] = var_name.strip()\n",
    "\n",
    "        # Define type conversion functions\n",
    "        if var_dtype == \"int\":\n",
    "            sT_type_conversion[full_var_name] = lambda s: pd.to_numeric(\n",
    "                s.map(handle_missing_values), errors=\"coerce\"\n",
    "            ).fillna(np.nan).astype(\"Int64\")\n",
    "\n",
    "        elif var_dtype == \"float\":\n",
    "            sT_type_conversion[full_var_name] = lambda s: pd.to_numeric(\n",
    "                s.map(handle_missing_values), errors=\"coerce\"\n",
    "            ).astype(float)\n",
    "\n",
    "        elif var_dtype == \"float-2\":\n",
    "            sT_type_conversion[full_var_name] = lambda s: pd.to_numeric(\n",
    "                s.map(handle_missing_values), errors=\"coerce\"\n",
    "            ).round(2)\n",
    "\n",
    "        elif var_dtype == \"bool\":\n",
    "            sT_type_conversion[full_var_name] = lambda s: s.map(convert_to_bool)\n",
    "\n",
    "        elif \"datetime\" in str(var_dtype):\n",
    "            format_map = {\n",
    "                \"dd.mm.yyyy\": \"%d.%m.%Y\",\n",
    "                \"yyyy-mm-dd\": \"%Y-%m-%d\",\n",
    "                \"yyyymmdd\": \"%Y%m%d\",\n",
    "                \"hh:mm:ss\": \"%H:%M:%S\",\n",
    "                \"hh:mm\": \"%H:%M\"\n",
    "            }\n",
    "\n",
    "            datetime_format = format_map.get(var_map, \"%Y%m%d\")\n",
    "            sT_datetime_formats[full_var_name] = datetime_format\n",
    "            sT_type_conversion[full_var_name] = safe_datetime_conversion\n",
    "\n",
    "        elif var_dtype == \"str\":\n",
    "            sT_type_conversion[full_var_name] = lambda s: s.astype(str).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secuTrial_w_REVAS_2 = df_secuTrial_w_REVAS.rename(columns=sT_mapping_dict)\n",
    "for col, converter in sT_type_conversion.items():\n",
    "    if col in df_secuTrial_w_REVAS_2.columns:\n",
    "        df_secuTrial_w_REVAS_2[col] = converter(df_secuTrial_w_REVAS_2[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EPIC data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_mapping.iterrows():\n",
    "    source_file = row[\"EPIC_exportFileName\"]\n",
    "    var_name = row[\"EPIC_varColumnName\"]\n",
    "    var_dtype = row[\"EPIC_varType\"]\n",
    "    secutrial_var = row.get(\"sT_varColumnName\", None)\n",
    "\n",
    "    # Prefix mapping\n",
    "    prefix_map = {\n",
    "        \"encounter\": \"enct.\",\n",
    "        \"flowsheet\": \"flow.\",\n",
    "        \"imaging\": \"img.\",\n",
    "        \"lab\": \"lab.\",\n",
    "        \"medication\": \"med.\",\n",
    "        \"monitor\": \"mon.\"\n",
    "    }\n",
    "    prefix = next((v for k, v in prefix_map.items() if isinstance(source_file, str) and k.lower() in source_file.lower()), \"\")\n",
    "\n",
    "    if pd.notna(var_name):\n",
    "        full_var_name = prefix + str(var_name)\n",
    "        ep_mapping_dict[full_var_name] = full_var_name\n",
    "\n",
    "        if var_dtype == \"int\":\n",
    "            ep_type_conversion[full_var_name] = lambda s: pd.to_numeric(\n",
    "                s.map(handle_missing_values), errors=\"coerce\"\n",
    "            ).fillna(pd.NA).astype(\"Int64\")  # Fixed conversion to support missing values\n",
    "\n",
    "        elif var_dtype == \"float\":\n",
    "            ep_type_conversion[full_var_name] = lambda s: pd.to_numeric(\n",
    "                s.map(handle_missing_values), errors=\"coerce\"\n",
    "            ).astype(float)\n",
    "\n",
    "        elif var_dtype == \"bool\":\n",
    "            ep_type_conversion[full_var_name] = lambda s: s.map(convert_to_bool)\n",
    "\n",
    "        elif \"datetime\" in str(var_dtype):\n",
    "            datetime_format = sT_datetime_formats.get(secutrial_var, \"%Y%m%d\")\n",
    "            ep_datetime_formats[full_var_name] = datetime_format\n",
    "            ep_type_conversion[full_var_name] = lambda s: safe_datetime_conversion(s, full_var_name, \"ep\")  # ✅ Now properly applied\n",
    "\n",
    "        elif var_dtype == \"str\":\n",
    "            ep_type_conversion[full_var_name] = lambda s: s.astype(str).fillna(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EPIC_all_2 = df_EPIC_all.rename(columns=ep_mapping_dict)\n",
    "\n",
    "for col, dtype in ep_type_conversion.items():\n",
    "    if col in df_EPIC_all_2.columns:\n",
    "        if dtype == \"bool\":\n",
    "            df_EPIC_all_2[col] = df_EPIC_all_2[col].map(convert_to_bool)\n",
    "        elif dtype == \"str\":\n",
    "            df_EPIC_all_2[col] = df_EPIC_all_2[col].astype(\"string\").fillna(\"\")\n",
    "        elif \"datetime\" in str(dtype):\n",
    "            df_EPIC_all_2[col] = safe_datetime_conversion(df_EPIC_all_2[col], col, \"ep\")\n",
    "        else:\n",
    "            df_EPIC_all_2[col] = safe_numeric_conversion(df_EPIC_all_2[col], dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Key!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reusable mappings\n",
    "yes_no_mapping = {0: 'no', 1: 'yes', False: 'no', True: 'yes'}\n",
    "bilateral_mapping = {0: 'no', 1: '', 2: 'right', 3: 'left', 4: 'bilateral'}\n",
    "prosthetic_valves_mapping = {0: 'None', 1: 'Biological', 2: 'Mechanical'}\n",
    "image_type_mapping = {1: 'CT', 2: 'MRI', 3: 'CT (external)', 4: 'MRI (external)', 1: 'CT-angiography', 2: 'MR-angiography'}\n",
    "transport_map = {1: 'Ambulance', 2: 'Helicopter', 3: 'Other (taxi,self,relatives,friends...)'}\n",
    "discharge_dest_map = {\n",
    "    1: 'Home', \n",
    "    3: 'Rehabilitation Hospital', \n",
    "    2: 'Other acute care hospital', \n",
    "    4: 'Nursing home, palliative care center, or other medical facility'\n",
    "}\n",
    "\n",
    "# Define common mappings for multiple columns\n",
    "yes_no_columns = [\n",
    "    'flow.iat_stentintracran', \n",
    "    'flow.iat_stentextracran', \n",
    "    'flow.stroke_pre', \n",
    "    'flow.tia_pre', \n",
    "    'flow.ich_pre',\n",
    "    'flow.hypertension', \n",
    "    'flow.diabetes', \n",
    "    'flow.hyperlipidemia', \n",
    "    'flow.smoking', \n",
    "    'flow.atrialfib', \n",
    "    'flow.chd',\n",
    "    'flow.lowoutput', \n",
    "    'flow.pad', \n",
    "    'flow.decompression', \n",
    "    'img.iat_mech', \n",
    "    'img.follow_mra', \n",
    "    'img.follow_cta',\n",
    "    'img.follow_ultrasound', \n",
    "    'img.follow_dsa', \n",
    "    'img.follow_tte', \n",
    "    'img.follow_tee', \n",
    "    'img.follow_holter',\n",
    "    'med.aspirin_pre', \n",
    "    'med.clopidogrel_pre', \n",
    "    'med.prasugrel_pre', \n",
    "    'med.ticagrelor_pre', \n",
    "    'med.dipyridamole_pre',\n",
    "    'med.vka_pre', \n",
    "    'med.rivaroxaban_pre', \n",
    "    'med.dabigatran_pre', \n",
    "    'med.apixaban_pre', \n",
    "    'med.edoxaban_pre',\n",
    "    'med.parenteralanticg_pre', \n",
    "    'med.antihypertensive_pre', \n",
    "    'med.antilipid_pre', \n",
    "    'med.hormone_pre',\n",
    "    'med.treat_antiplatelet', \n",
    "    'med.treat_anticoagulant', \n",
    "    'med.treat_ivt'\n",
    "]\n",
    "\n",
    "bilateral_columns = ['flow.mca', 'flow.aca', 'flow.pca', 'flow.vertebrobasilar']\n",
    "\n",
    "# Define value mappings for specific columns\n",
    "value_mappings = {\n",
    "    'enct.non_swiss': {True: 'yes'},\n",
    "    'enct.sex': {1: 'Male', 2: 'Female'},\n",
    "    'enct.transport': transport_map,\n",
    "    'enct.discharge_destinat': discharge_dest_map,  # Double-check mapping values\n",
    "    'flow.firstangio_result': {2: 'no', 3: 'yes'},  # Double-check mapping values\n",
    "    'flow.prostheticvalves': prosthetic_valves_mapping,\n",
    "    'img.firstimage_type': image_type_mapping,\n",
    "    'img.firstangio_type': image_type_mapping\n",
    "}\n",
    "\n",
    "# Apply yes_no_mapping and bilateral_mapping to multiple columns dynamically\n",
    "value_mappings.update({col: yes_no_mapping for col in yes_no_columns})\n",
    "value_mappings.update({col: bilateral_mapping for col in bilateral_columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare ep and sT dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main functioning one\n",
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    but only for rows where FID and SSR match in both datasets.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "    \"\"\"\n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    epic_df.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df.columns or \"SSR\" not in epic_df.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df.columns or \"SSR\" not in secuTrial_df.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Apply value mappings to EPIC data before comparison and print changes\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df.columns:\n",
    "            #print(f\"\\n🔹 Applying mapping to column: {col}\")\n",
    "            #print(\"Before Mapping:\")\n",
    "            #print(epic_df[col].value_counts(dropna=False))  # Show initial value distribution\n",
    "        \n",
    "            # Apply mapping\n",
    "            epic_df[col] = epic_df[col].map(mapping).fillna(epic_df[col])  \n",
    "            epic_df[col] = epic_df[col].astype(str)  # Ensure string for comparison\n",
    "\n",
    "            #print(\"\\nAfter Mapping:\")\n",
    "            #print(epic_df[col].value_counts(dropna=False))  # Show transformed value distribution\n",
    "    \n",
    "    # Iterate through the mapping file to compare columns\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', None)\n",
    "        secuTrial_dtype = row.get('sT_varType', None)\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "\n",
    "        # Count missing variables\n",
    "        if epic_col not in epic_df.columns and secu_col in secuTrial_df.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df.columns and epic_col in epic_df.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df.columns and secu_col not in secuTrial_df.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_value = epic_df.loc[(epic_df[\"FID\"] == fid) & (epic_df[\"SSR\"] == ssr), epic_col].values\n",
    "            secu_value = secuTrial_df.loc[(secuTrial_df[\"FID\"] == fid) & (secuTrial_df[\"SSR\"] == ssr), secu_col].values\n",
    "\n",
    "            if len(epic_value) == 0 or len(secu_value) == 0:\n",
    "                continue  # Skip if value is missing in either DataFrame\n",
    "\n",
    "            # Convert both values to string before comparing\n",
    "            epic_value_str = str(epic_value[0])\n",
    "            secu_value_str = str(secu_value[0])\n",
    "\n",
    "            # Check if SecuTrial value is NaN or NaT\n",
    "            if pd.isna(secu_value[0]):\n",
    "                secu_missing_count += 1\n",
    "                continue  # Skip further comparison for this case\n",
    "\n",
    "            if epic_value_str == secu_value_str:\n",
    "                match_count += 1\n",
    "            else:  # Store mismatched results\n",
    "                mismatch_count += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': epic_value_str,\n",
    "                    'SecuTrial Value': secu_value_str,\n",
    "                    'EPIC Data Type': str(epic_df[epic_col].dtype),\n",
    "                    'SecuTrial Data Type': str(secuTrial_df[secu_col].dtype)\n",
    "                })\n",
    "\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_vars = match_count + secu_missing_count + epic_missing_count + mismatch_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_vars) * 100, 2) if total_vars else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_vars) * 100, 2) if total_vars else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_vars) * 100, 2) if total_vars else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_vars) * 100, 2) if total_vars else 0\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude code - 20250227\n",
    "\n",
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                return pd.to_datetime(value) if value else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            if isinstance(value, bool):\n",
    "                return value\n",
    "            elif isinstance(value, (int, float)):\n",
    "                return bool(value)\n",
    "            elif isinstance(value, str):\n",
    "                return value.lower() in ['true', 'yes', 'y', '1', 't']\n",
    "            else:\n",
    "                return pd.NA\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2, epic_type, secu_type):\n",
    "        \"\"\"Compare values with type awareness\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Special handling for numeric types\n",
    "        if epic_type.lower() in ['int', 'integer', 'float', 'double', 'numeric', 'int64', 'int32', 'float64', 'float32'] and \\\n",
    "           secu_type.lower() in ['int', 'integer', 'float', 'double', 'numeric', 'int64', 'int32', 'float64', 'float32']:\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison\n",
    "        elif epic_type.lower() in ['date', 'datetime', 'timestamp'] and \\\n",
    "             secu_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                dt1 = pd.to_datetime(val1)\n",
    "                dt2 = pd.to_datetime(val2)\n",
    "                return dt1 == dt2\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "                \n",
    "        # Boolean comparison\n",
    "        elif epic_type.lower() in ['bool', 'boolean'] and \\\n",
    "             secu_type.lower() in ['bool', 'boolean']:\n",
    "            bool_truthy = ['true', 'yes', 'y', '1', 't', 'True', 'TRUE', 1, True]\n",
    "            bool_falsy = ['false', 'no', 'n', '0', 'f', 'False', 'FALSE', 0, False]\n",
    "            \n",
    "            val1_bool = val1 in bool_truthy\n",
    "            val2_bool = val2 in bool_truthy\n",
    "            return val1_bool == val2_bool\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Apply value mappings to EPIC data before comparison\n",
    "    modified_columns = set()\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "            modified_columns.add(col)\n",
    "    \n",
    "    # Iterate through the mapping file to compare columns\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "\n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row else pd.NA\n",
    "            \n",
    "            # Skip comparison if both values are missing\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if SecuTrial value is NaN\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if EPIC value is NaN\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Convert values according to their intended data types\n",
    "            epic_value_converted = convert_to_type(epic_value, epic_dtype)\n",
    "            secu_value_converted = convert_to_type(secu_value, secuTrial_dtype)\n",
    "            \n",
    "            # Compare values with type awareness\n",
    "            if equivalent_values(epic_value_converted, secu_value_converted, epic_dtype, secuTrial_dtype):\n",
    "                match_count += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': epic_dtype,\n",
    "                    'SecuTrial Expected Type': secuTrial_dtype,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude code 2\n",
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                return pd.to_datetime(value) if value else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            if isinstance(value, bool):\n",
    "                return value\n",
    "            elif isinstance(value, (int, float)):\n",
    "                return bool(value)\n",
    "            elif isinstance(value, str):\n",
    "                return value.lower() in ['true', 'yes', 'y', '1', 't']\n",
    "            else:\n",
    "                return pd.NA\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2):\n",
    "        \"\"\"Compare values directly\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Special handling for numeric types\n",
    "        if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison\n",
    "        elif isinstance(val1, pd.Timestamp) and isinstance(val2, pd.Timestamp):\n",
    "            return val1 == val2\n",
    "                \n",
    "        # Boolean comparison\n",
    "        elif isinstance(val1, bool) and isinstance(val2, bool):\n",
    "            return val1 == val2\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Build a column mapping dictionary for easier lookups\n",
    "    column_mappings = {}\n",
    "    column_types = {}\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "        \n",
    "        # Store the mapping\n",
    "        column_mappings[epic_col] = secu_col\n",
    "        column_types[epic_col] = {'epic_type': epic_dtype, 'secu_type': secuTrial_dtype}\n",
    "    \n",
    "    # First, apply value mappings to EPIC data\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "    \n",
    "    # Next, convert EPIC data types to match secuTrial types\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        if epic_col in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['secu_type']\n",
    "            epic_df_copy[epic_col] = epic_df_copy[epic_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "    \n",
    "    # Now compare the values\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "        \n",
    "        # Get data types for this column pair\n",
    "        epic_dtype = column_types[epic_col]['epic_type']\n",
    "        secuTrial_dtype = column_types[epic_col]['secu_type']\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row else pd.NA\n",
    "            \n",
    "            # Skip comparison if both values are missing\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if SecuTrial value is NaN\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if EPIC value is NaN\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Compare values directly (no need to convert again)\n",
    "            if equivalent_values(epic_value, secu_value):\n",
    "                match_count += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': epic_dtype,\n",
    "                    'SecuTrial Expected Type': secuTrial_dtype,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude code 3\n",
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type with specific formatting\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return value\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower())\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                float_val = float(value)\n",
    "                return round(float_val, decimal_places)\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                # Convert to datetime and then to yyyymmdd hh:mm format\n",
    "                dt = pd.to_datetime(value)\n",
    "                return dt.strftime('%Y%m%d %H:%M')\n",
    "            except (ValueError, TypeError, AttributeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            if isinstance(value, bool):\n",
    "                return value\n",
    "            elif isinstance(value, (int, float)):\n",
    "                return bool(value)\n",
    "            elif isinstance(value, str):\n",
    "                return value.lower() in ['true', 'yes', 'y', '1', 't']\n",
    "            else:\n",
    "                return pd.NA\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2, target_type):\n",
    "        \"\"\"Compare values with formatted type awareness\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower()) if isinstance(target_type, str) else None\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                val1_rounded = round(float(val1), decimal_places)\n",
    "                val2_rounded = round(float(val2), decimal_places)\n",
    "                return val1_rounded == val2_rounded\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Special handling for numeric types\n",
    "        if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison (already in string format)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            return val1 == val2\n",
    "                \n",
    "        # Boolean comparison\n",
    "        elif isinstance(val1, bool) and isinstance(val2, bool):\n",
    "            return val1 == val2\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Build a column mapping dictionary for easier lookups\n",
    "    column_mappings = {}\n",
    "    column_types = {}\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "        \n",
    "        # If secuTrial type is int, override EPIC type to also be int\n",
    "        if secuTrial_dtype.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            epic_dtype = 'int'\n",
    "        # If secuTrial type is float or float-n, override EPIC type\n",
    "        elif secuTrial_dtype.lower() in ['float', 'double', 'numeric', 'float64', 'float32'] or re.match(r'float-\\d+', secuTrial_dtype.lower()):\n",
    "            epic_dtype = secuTrial_dtype\n",
    "        \n",
    "        # Store the mapping\n",
    "        column_mappings[epic_col] = secu_col\n",
    "        column_types[epic_col] = {'epic_type': epic_dtype, 'secu_type': secuTrial_dtype}\n",
    "    \n",
    "    # First, apply value mappings to EPIC data\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "    \n",
    "    # Next, convert data types in both dataframes\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # For EPIC dataframe\n",
    "        if epic_col in epic_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['epic_type']\n",
    "            epic_df_copy[epic_col] = epic_df_copy[epic_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "        \n",
    "        # For secuTrial dataframe\n",
    "        if secu_col in secuTrial_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['secu_type']\n",
    "            secuTrial_df_copy[secu_col] = secuTrial_df_copy[secu_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "    \n",
    "    # Now compare the values\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "        \n",
    "        # Get target type for this column\n",
    "        target_type = column_types[epic_col]['secu_type']  # Use secuTrial type as the target\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row.columns else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row.columns else pd.NA\n",
    "            \n",
    "            # Skip comparison if both values are missing\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if SecuTrial value is NaN\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Skip and count as missing if EPIC value is NaN\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Compare values using the target type\n",
    "            if equivalent_values(epic_value, secu_value, target_type):\n",
    "                match_count += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': column_types[epic_col]['epic_type'],\n",
    "                    'SecuTrial Expected Type': target_type,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude code 4\n",
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Helper function to standardize boolean values\n",
    "    def standardize_boolean(value):\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "        \n",
    "        if isinstance(value, bool):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, str):\n",
    "            if value.lower() in ['true', 'yes', 'y', '1', 't']:\n",
    "                return \"yes\"\n",
    "            elif value.lower() in ['false', 'no', 'n', '0', 'f']:\n",
    "                return \"no\"\n",
    "        \n",
    "        return str(value)\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type with specific formatting\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower())\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                float_val = float(value)\n",
    "                return round(float_val, decimal_places)\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                # Convert to datetime and then to yyyymmdd hh:mm format\n",
    "                dt = pd.to_datetime(value)\n",
    "                return dt.strftime('%Y%m%d %H:%M')\n",
    "            except (ValueError, TypeError, AttributeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            return standardize_boolean(value)\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None and value != '' else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2, target_type):\n",
    "        \"\"\"Compare values with formatted type awareness\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower()) if isinstance(target_type, str) else None\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                val1_rounded = round(float(val1), decimal_places)\n",
    "                val2_rounded = round(float(val2), decimal_places)\n",
    "                return val1_rounded == val2_rounded\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Boolean comparison (standardized to yes/no)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['bool', 'boolean']:\n",
    "            val1_std = standardize_boolean(val1)\n",
    "            val2_std = standardize_boolean(val2)\n",
    "            return val1_std == val2_std\n",
    "        \n",
    "        # Special handling for numeric types\n",
    "        if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison (already in string format)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            return val1 == val2\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Build a column mapping dictionary for easier lookups\n",
    "    column_mappings = {}\n",
    "    column_types = {}\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "        \n",
    "        # If secuTrial type is int, override EPIC type to also be int\n",
    "        if secuTrial_dtype.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            epic_dtype = 'int'\n",
    "        # If secuTrial type is float or float-n, override EPIC type\n",
    "        elif secuTrial_dtype.lower() in ['float', 'double', 'numeric', 'float64', 'float32'] or re.match(r'float-\\d+', secuTrial_dtype.lower()):\n",
    "            epic_dtype = secuTrial_dtype\n",
    "        \n",
    "        # Store the mapping\n",
    "        column_mappings[epic_col] = secu_col\n",
    "        column_types[epic_col] = {'epic_type': epic_dtype, 'secu_type': secuTrial_dtype}\n",
    "    \n",
    "    # First, apply value mappings to EPIC data\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "    \n",
    "    # Next, convert data types in both dataframes\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # For EPIC dataframe\n",
    "        if epic_col in epic_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['epic_type']\n",
    "            epic_df_copy[epic_col] = epic_df_copy[epic_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "        \n",
    "        # For secuTrial dataframe\n",
    "        if secu_col in secuTrial_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['secu_type']\n",
    "            secuTrial_df_copy[secu_col] = secuTrial_df_copy[secu_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "    \n",
    "    # Now compare the values\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "        \n",
    "        # Get target type for this column\n",
    "        target_type = column_types[epic_col]['secu_type']  # Use secuTrial type as the target\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row.columns else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row.columns else pd.NA\n",
    "            \n",
    "            # Both values are NaN/missing - count as match\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Only secuTrial value is NaN/missing\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Only EPIC value is NaN/missing\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                continue\n",
    "\n",
    "            # Compare values using the target type\n",
    "            if equivalent_values(epic_value, secu_value, target_type):\n",
    "                match_count += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': column_types[epic_col]['epic_type'],\n",
    "                    'SecuTrial Expected Type': target_type,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly. Includes monthly breakdown of statistics.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "        dict: Dictionary containing monthly statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "        \n",
    "    # Modify line ~40-43 in the function\n",
    "    if \"enct.arrival_date\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'enct.arrival_date' column for monthly breakdown.\")\n",
    "    if \"Arrival at hospital\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'Arrival at hospital' column for monthly breakdown.\")\n",
    "\n",
    "    # And then use these columns for date conversion ~46-47\n",
    "    epic_df_copy['DATE'] = pd.to_datetime(epic_df_copy['enct.arrival_date'], errors='coerce')\n",
    "    secuTrial_df_copy['DATE'] = pd.to_datetime(secuTrial_df_copy['Arrival at hospital'], errors='coerce')\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Setup monthly statistics tracking\n",
    "    months = {4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', \n",
    "              9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    \n",
    "    monthly_stats = {month_name: {'match_count': 0, 'secu_missing_count': 0, \n",
    "                                'epic_missing_count': 0, 'mismatch_count': 0, \n",
    "                                'total_compared': 0} \n",
    "                   for month_name in months.values()}\n",
    "    \n",
    "    # Helper function to standardize boolean values\n",
    "    def standardize_boolean(value):\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "        \n",
    "        if isinstance(value, bool):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, str):\n",
    "            if value.lower() in ['true', 'yes', 'y', '1', 't']:\n",
    "                return \"yes\"\n",
    "            elif value.lower() in ['false', 'no', 'n', '0', 'f']:\n",
    "                return \"no\"\n",
    "        \n",
    "        return str(value)\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type with specific formatting\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower())\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                float_val = float(value)\n",
    "                return round(float_val, decimal_places)\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                # Convert to datetime and then to yyyymmdd hh:mm format\n",
    "                dt = pd.to_datetime(value)\n",
    "                return dt.strftime('%Y%m%d %H:%M')\n",
    "            except (ValueError, TypeError, AttributeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            return standardize_boolean(value)\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None and value != '' else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2, target_type):\n",
    "        \"\"\"Compare values with formatted type awareness\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower()) if isinstance(target_type, str) else None\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                val1_rounded = round(float(val1), decimal_places)\n",
    "                val2_rounded = round(float(val2), decimal_places)\n",
    "                return val1_rounded == val2_rounded\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Boolean comparison (standardized to yes/no)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['bool', 'boolean']:\n",
    "            val1_std = standardize_boolean(val1)\n",
    "            val2_std = standardize_boolean(val2)\n",
    "            return val1_std == val2_std\n",
    "        \n",
    "        # Special handling for numeric types\n",
    "        if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison (already in string format)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            return val1 == val2\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Build a column mapping dictionary for easier lookups\n",
    "    column_mappings = {}\n",
    "    column_types = {}\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "        \n",
    "        # If secuTrial type is int, override EPIC type to also be int\n",
    "        if secuTrial_dtype.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            epic_dtype = 'int'\n",
    "        # If secuTrial type is float or float-n, override EPIC type\n",
    "        elif secuTrial_dtype.lower() in ['float', 'double', 'numeric', 'float64', 'float32'] or re.match(r'float-\\d+', secuTrial_dtype.lower()):\n",
    "            epic_dtype = secuTrial_dtype\n",
    "        \n",
    "        # Store the mapping\n",
    "        column_mappings[epic_col] = secu_col\n",
    "        column_types[epic_col] = {'epic_type': epic_dtype, 'secu_type': secuTrial_dtype}\n",
    "    \n",
    "    # First, apply value mappings to EPIC data\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "    \n",
    "    # Next, convert data types in both dataframes\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # For EPIC dataframe\n",
    "        if epic_col in epic_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['epic_type']\n",
    "            epic_df_copy[epic_col] = epic_df_copy[epic_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "        \n",
    "        # For secuTrial dataframe\n",
    "        if secu_col in secuTrial_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['secu_type']\n",
    "            secuTrial_df_copy[secu_col] = secuTrial_df_copy[secu_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "    \n",
    "    # Now compare the values\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "        \n",
    "        # Get target type for this column\n",
    "        target_type = column_types[epic_col]['secu_type']  # Use secuTrial type as the target\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row.columns else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row.columns else pd.NA\n",
    "            \n",
    "            # Get the month for this record (use epic date if available, else secu date)\n",
    "            record_date = None\n",
    "            if not epic_row.empty and 'DATE' in epic_row.columns and not pd.isna(epic_row['DATE'].iloc[0]):\n",
    "                record_date = epic_row['DATE'].iloc[0]\n",
    "            elif not secu_row.empty and 'DATE' in secu_row.columns and not pd.isna(secu_row['DATE'].iloc[0]):\n",
    "                record_date = secu_row['DATE'].iloc[0]\n",
    "                \n",
    "            # Skip if no valid date or not in April-December range\n",
    "            if record_date is None:\n",
    "                continue\n",
    "                \n",
    "            record_month = record_date.month\n",
    "            # Skip if not in our target month range (April-December)\n",
    "            if record_month < 4 or record_month > 12:\n",
    "                continue\n",
    "                \n",
    "            month_name = months[record_month]\n",
    "                \n",
    "            # Both values are NaN/missing - count as match\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                monthly_stats[month_name]['match_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                continue\n",
    "                \n",
    "            # Only secuTrial value is NaN/missing\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                monthly_stats[month_name]['secu_missing_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                continue\n",
    "                \n",
    "            # Only EPIC value is NaN/missing\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                monthly_stats[month_name]['epic_missing_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                continue\n",
    "\n",
    "            # Compare values using the target type\n",
    "            if equivalent_values(epic_value, secu_value, target_type):\n",
    "                match_count += 1\n",
    "                monthly_stats[month_name]['match_count'] += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                monthly_stats[month_name]['mismatch_count'] += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'Month': month_name,\n",
    "                    'DATE': record_date,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': column_types[epic_col]['epic_type'],\n",
    "                    'SecuTrial Expected Type': target_type,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "            \n",
    "            monthly_stats[month_name]['total_compared'] += 1\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "    \n",
    "    # Calculate monthly percentages\n",
    "    monthly_percentage_stats = {}\n",
    "    for month, stats in monthly_stats.items():\n",
    "        total = stats['total_compared']\n",
    "        if total > 0:\n",
    "            monthly_percentage_stats[month] = {\n",
    "                \"Matching Variables (%)\": round((stats['match_count'] / total) * 100, 2),\n",
    "                \"Variables Missing in EPIC (%)\": round((stats['epic_missing_count'] / total) * 100, 2),\n",
    "                \"Variables Missing in SecuTrial (%)\": round((stats['secu_missing_count'] / total) * 100, 2),\n",
    "                \"Mismatched Variables (%)\": round((stats['mismatch_count'] / total) * 100, 2),\n",
    "                \"Total Comparisons\": total,\n",
    "                \"Matches\": stats['match_count'],\n",
    "                \"EPIC Missing\": stats['epic_missing_count'],\n",
    "                \"SecuTrial Missing\": stats['secu_missing_count'],\n",
    "                \"Mismatches\": stats['mismatch_count']\n",
    "            }\n",
    "        else:\n",
    "            monthly_percentage_stats[month] = {\n",
    "                \"Matching Variables (%)\": 0,\n",
    "                \"Variables Missing in EPIC (%)\": 0,\n",
    "                \"Variables Missing in SecuTrial (%)\": 0,\n",
    "                \"Mismatched Variables (%)\": 0,\n",
    "                \"Total Comparisons\": 0,\n",
    "                \"Matches\": 0,\n",
    "                \"EPIC Missing\": 0,\n",
    "                \"SecuTrial Missing\": 0,\n",
    "                \"Mismatches\": 0\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats, monthly_percentage_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_epic_secuTrial(epic_df, secuTrial_df, mapping_df, value_mappings=None):\n",
    "    \"\"\"\n",
    "    Compares values and data types between EPIC and secuTrial DataFrames using a mapping file,\n",
    "    accounting for data type differences properly. Includes monthly breakdown of statistics\n",
    "    and variable-level statistics.\n",
    "\n",
    "    Args:\n",
    "        epic_df (DataFrame): The EPIC dataset.\n",
    "        secuTrial_df (DataFrame): The SecuTrial dataset.\n",
    "        mapping_df (DataFrame): The mapping Excel file with data type information.\n",
    "        value_mappings (dict, optional): Dictionary for value conversions in EPIC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with mismatched results in values and data types.\n",
    "        dict: Dictionary containing percentage statistics.\n",
    "        dict: Dictionary containing monthly statistics.\n",
    "        dict: Dictionary containing variable-level statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if value_mappings is None:\n",
    "        value_mappings = {}\n",
    "        \n",
    "    # Create working copies to avoid modifying original dataframes\n",
    "    epic_df_copy = epic_df.copy()\n",
    "    secuTrial_df_copy = secuTrial_df.copy()\n",
    "    \n",
    "    # Replace missing value indicators\n",
    "    epic_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "    secuTrial_df_copy.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "    # Ensure necessary columns exist before comparison\n",
    "    if \"FID\" not in epic_df_copy.columns or \"SSR\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "    if \"FID\" not in secuTrial_df_copy.columns or \"SSR\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'FID' and 'SSR' columns.\")\n",
    "        \n",
    "    # Modify line ~40-43 in the function\n",
    "    if \"enct.arrival_date\" not in epic_df_copy.columns:\n",
    "        raise ValueError(\"EPIC DataFrame must contain 'enct.arrival_date' column for monthly breakdown.\")\n",
    "    if \"Arrival at hospital\" not in secuTrial_df_copy.columns:\n",
    "        raise ValueError(\"SecuTrial DataFrame must contain 'Arrival at hospital' column for monthly breakdown.\")\n",
    "\n",
    "    # And then use these columns for date conversion ~46-47\n",
    "    epic_df_copy['DATE'] = pd.to_datetime(epic_df_copy['enct.arrival_date'], errors='coerce')\n",
    "    secuTrial_df_copy['DATE'] = pd.to_datetime(secuTrial_df_copy['Arrival at hospital'], errors='coerce')\n",
    "\n",
    "    # Create a set of (FID, SSR) pairs that exist in both DataFrames\n",
    "    matching_keys = set(epic_df_copy[['FID', 'SSR']].apply(tuple, axis=1)) & set(secuTrial_df_copy[['FID', 'SSR']].apply(tuple, axis=1))\n",
    "\n",
    "    # Store mismatched results\n",
    "    mismatched_results = []\n",
    "    match_count = 0\n",
    "    secu_missing_count = 0\n",
    "    epic_missing_count = 0\n",
    "    mismatch_count = 0\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    # Setup monthly statistics tracking\n",
    "    months = {4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', \n",
    "              9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
    "    \n",
    "    monthly_stats = {month_name: {'match_count': 0, 'secu_missing_count': 0, \n",
    "                                'epic_missing_count': 0, 'mismatch_count': 0, \n",
    "                                'total_compared': 0} \n",
    "                   for month_name in months.values()}\n",
    "    \n",
    "    # Create a dictionary to store variable-level statistics\n",
    "    variable_stats = {}\n",
    "    \n",
    "    # Helper function to standardize boolean values\n",
    "    def standardize_boolean(value):\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "        \n",
    "        if isinstance(value, bool):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, (int, float)):\n",
    "            return \"yes\" if value else \"no\"\n",
    "        elif isinstance(value, str):\n",
    "            if value.lower() in ['true', 'yes', 'y', '1', 't']:\n",
    "                return \"yes\"\n",
    "            elif value.lower() in ['false', 'no', 'n', '0', 'f']:\n",
    "                return \"no\"\n",
    "        \n",
    "        return str(value)\n",
    "    \n",
    "    # Helper function to convert values to the correct type\n",
    "    def convert_to_type(value, target_type):\n",
    "        \"\"\"Convert value to specified type with specific formatting\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "            \n",
    "        # Handle various data types\n",
    "        if not isinstance(target_type, str):\n",
    "            return value  # If no type specified, return as is\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower())\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                float_val = float(value)\n",
    "                return round(float_val, decimal_places)\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        \n",
    "        if target_type.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            try:\n",
    "                return int(float(value)) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['float', 'double', 'numeric', 'float64', 'float32']:\n",
    "            try:\n",
    "                return float(value) if value != '' else pd.NA\n",
    "            except (ValueError, TypeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            try:\n",
    "                if value == '':\n",
    "                    return pd.NA\n",
    "                # Convert to datetime and then to yyyymmdd hh:mm format\n",
    "                dt = pd.to_datetime(value)\n",
    "                return dt.strftime('%Y%m%d %H:%M')\n",
    "            except (ValueError, TypeError, AttributeError):\n",
    "                return pd.NA\n",
    "        elif target_type.lower() in ['bool', 'boolean']:\n",
    "            return standardize_boolean(value)\n",
    "        else:\n",
    "            # Default to string for text, categorical, etc.\n",
    "            return str(value) if value is not None and value != '' else pd.NA\n",
    "    \n",
    "    # Helper function to check if values are equivalent\n",
    "    def equivalent_values(val1, val2, target_type):\n",
    "        \"\"\"Compare values with formatted type awareness\"\"\"\n",
    "        # Handle NaN values consistently\n",
    "        if pd.isna(val1) and pd.isna(val2):\n",
    "            return True\n",
    "        elif pd.isna(val1) or pd.isna(val2):\n",
    "            return False\n",
    "            \n",
    "        # Check for float with decimal specification (e.g., float-1, float-2)\n",
    "        float_match = re.match(r'float-(\\d+)', target_type.lower()) if isinstance(target_type, str) else None\n",
    "        if float_match:\n",
    "            try:\n",
    "                decimal_places = int(float_match.group(1))\n",
    "                val1_rounded = round(float(val1), decimal_places)\n",
    "                val2_rounded = round(float(val2), decimal_places)\n",
    "                return val1_rounded == val2_rounded\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Boolean comparison (standardized to yes/no)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['bool', 'boolean']:\n",
    "            val1_std = standardize_boolean(val1)\n",
    "            val2_std = standardize_boolean(val2)\n",
    "            return val1_std == val2_std\n",
    "        \n",
    "        # Special handling for numeric types\n",
    "        if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):\n",
    "            try:\n",
    "                return abs(float(val1) - float(val2)) < 1e-6\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "        \n",
    "        # Date comparison (already in string format)\n",
    "        if isinstance(target_type, str) and target_type.lower() in ['date', 'datetime', 'timestamp']:\n",
    "            return val1 == val2\n",
    "            \n",
    "        # String comparison (case insensitive)\n",
    "        elif isinstance(val1, str) and isinstance(val2, str):\n",
    "            return val1.strip().lower() == val2.strip().lower()\n",
    "            \n",
    "        # Default comparison\n",
    "        else:\n",
    "            return str(val1) == str(val2)\n",
    "    \n",
    "    # Build a column mapping dictionary for easier lookups\n",
    "    column_mappings = {}\n",
    "    column_types = {}\n",
    "    \n",
    "    for _, row in mapping_df.iterrows():\n",
    "        epic_column_name = row.get('EPIC_varColumnName', None)\n",
    "        secuTrial_column_name = row.get('sT_varColumnName', None)\n",
    "        epic_dtype = row.get('EPIC_varType', 'text')  # Default to text if not specified\n",
    "        secuTrial_dtype = row.get('sT_varType', 'text')  # Default to text if not specified\n",
    "        column_source = row.get('EPIC_exportFileName', None)\n",
    "        secu_source = row.get('sT_exportFileName', None)\n",
    "\n",
    "        if not isinstance(epic_column_name, str) or not isinstance(secuTrial_column_name, str):\n",
    "            continue  # Skip if column names are missing\n",
    "\n",
    "        # Determine EPIC column prefix\n",
    "        prefix = \"\"\n",
    "        if isinstance(column_source, str):\n",
    "            if \"encounter\" in column_source:\n",
    "                prefix = \"enct.\"\n",
    "            elif \"flowsheet\" in column_source:\n",
    "                prefix = \"flow.\"\n",
    "            elif \"imaging\" in column_source:\n",
    "                prefix = \"img.\"\n",
    "            elif \"lab\" in column_source:\n",
    "                prefix = \"lab.\"\n",
    "            elif \"medication\" in column_source:\n",
    "                prefix = \"med.\"\n",
    "            elif \"monitor\" in column_source:\n",
    "                prefix = \"mon.\"\n",
    "\n",
    "        # Determine SecuTrial column suffix\n",
    "        suffix = \"\"\n",
    "        if isinstance(secu_source, str) and \"REVASC\" in secu_source:\n",
    "            suffix = \".revas\"\n",
    "\n",
    "        # Construct fully qualified column names\n",
    "        epic_col = f\"{prefix}{epic_column_name}\"  # EPIC column with prefix\n",
    "        secu_col = f\"{secuTrial_column_name}{suffix}\"  # SecuTrial column with suffix\n",
    "        \n",
    "        # If secuTrial type is int, override EPIC type to also be int\n",
    "        if secuTrial_dtype.lower() in ['int', 'integer', 'int64', 'int32']:\n",
    "            epic_dtype = 'int'\n",
    "        # If secuTrial type is float or float-n, override EPIC type\n",
    "        elif secuTrial_dtype.lower() in ['float', 'double', 'numeric', 'float64', 'float32'] or re.match(r'float-\\d+', secuTrial_dtype.lower()):\n",
    "            epic_dtype = secuTrial_dtype\n",
    "        \n",
    "        # Store the mapping\n",
    "        column_mappings[epic_col] = secu_col\n",
    "        column_types[epic_col] = {'epic_type': epic_dtype, 'secu_type': secuTrial_dtype}\n",
    "        \n",
    "        # Initialize variable stats for this column pair\n",
    "        variable_stats[f\"{epic_col} <-> {secu_col}\"] = {\n",
    "            'match_count': 0,\n",
    "            'epic_missing_count': 0,\n",
    "            'secu_missing_count': 0,\n",
    "            'mismatch_count': 0,\n",
    "            'total_compared': 0,\n",
    "            'epic_type': epic_dtype,\n",
    "            'secu_type': secuTrial_dtype\n",
    "        }\n",
    "    \n",
    "    # First, apply value mappings to EPIC data\n",
    "    for col, mapping in value_mappings.items():\n",
    "        if col in epic_df_copy.columns:\n",
    "            epic_df_copy[col] = epic_df_copy[col].map(lambda x: mapping.get(x, x))\n",
    "    \n",
    "    # Next, convert data types in both dataframes\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        # For EPIC dataframe\n",
    "        if epic_col in epic_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['epic_type']\n",
    "            epic_df_copy[epic_col] = epic_df_copy[epic_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "        \n",
    "        # For secuTrial dataframe\n",
    "        if secu_col in secuTrial_df_copy.columns:\n",
    "            target_type = column_types[epic_col]['secu_type']\n",
    "            secuTrial_df_copy[secu_col] = secuTrial_df_copy[secu_col].apply(lambda x: convert_to_type(x, target_type))\n",
    "    \n",
    "    # Now compare the values\n",
    "    for epic_col, secu_col in column_mappings.items():\n",
    "        var_key = f\"{epic_col} <-> {secu_col}\"\n",
    "        \n",
    "        # Check if columns exist in respective DataFrames\n",
    "        if epic_col not in epic_df_copy.columns and secu_col in secuTrial_df_copy.columns:\n",
    "            epic_missing_count += 1\n",
    "            variable_stats[var_key]['epic_missing_count'] += 1\n",
    "            variable_stats[var_key]['total_compared'] += 1\n",
    "            continue\n",
    "        elif secu_col not in secuTrial_df_copy.columns and epic_col in epic_df_copy.columns:\n",
    "            secu_missing_count += 1\n",
    "            variable_stats[var_key]['secu_missing_count'] += 1\n",
    "            variable_stats[var_key]['total_compared'] += 1\n",
    "            continue\n",
    "        elif epic_col not in epic_df_copy.columns and secu_col not in secuTrial_df_copy.columns:\n",
    "            continue  # Skip comparison if column is missing in both\n",
    "\n",
    "        total_comparisons += 1\n",
    "        \n",
    "        # Get target type for this column\n",
    "        target_type = column_types[epic_col]['secu_type']  # Use secuTrial type as the target\n",
    "\n",
    "        # Compare values for rows with matching (FID, SSR)\n",
    "        for fid, ssr in matching_keys:\n",
    "            epic_row = epic_df_copy.loc[(epic_df_copy[\"FID\"] == fid) & (epic_df_copy[\"SSR\"] == ssr)]\n",
    "            secu_row = secuTrial_df_copy.loc[(secuTrial_df_copy[\"FID\"] == fid) & (secuTrial_df_copy[\"SSR\"] == ssr)]\n",
    "            \n",
    "            if epic_row.empty or secu_row.empty:\n",
    "                continue  # Skip if no matching row found\n",
    "                \n",
    "            epic_value = epic_row[epic_col].iloc[0] if epic_col in epic_row.columns else pd.NA\n",
    "            secu_value = secu_row[secu_col].iloc[0] if secu_col in secu_row.columns else pd.NA\n",
    "            \n",
    "            # Get the month for this record (use epic date if available, else secu date)\n",
    "            record_date = None\n",
    "            if not epic_row.empty and 'DATE' in epic_row.columns and not pd.isna(epic_row['DATE'].iloc[0]):\n",
    "                record_date = epic_row['DATE'].iloc[0]\n",
    "            elif not secu_row.empty and 'DATE' in secu_row.columns and not pd.isna(secu_row['DATE'].iloc[0]):\n",
    "                record_date = secu_row['DATE'].iloc[0]\n",
    "                \n",
    "            # Skip if no valid date or not in April-December range\n",
    "            if record_date is None:\n",
    "                continue\n",
    "                \n",
    "            record_month = record_date.month\n",
    "            # Skip if not in our target month range (April-December)\n",
    "            if record_month < 4 or record_month > 12:\n",
    "                continue\n",
    "                \n",
    "            month_name = months[record_month]\n",
    "                \n",
    "            # Both values are NaN/missing - count as match\n",
    "            if pd.isna(epic_value) and pd.isna(secu_value):\n",
    "                match_count += 1\n",
    "                monthly_stats[month_name]['match_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                variable_stats[var_key]['match_count'] += 1\n",
    "                variable_stats[var_key]['total_compared'] += 1\n",
    "                continue\n",
    "                \n",
    "            # Only secuTrial value is NaN/missing\n",
    "            if pd.isna(secu_value) and not pd.isna(epic_value):\n",
    "                secu_missing_count += 1\n",
    "                monthly_stats[month_name]['secu_missing_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                variable_stats[var_key]['secu_missing_count'] += 1\n",
    "                variable_stats[var_key]['total_compared'] += 1\n",
    "                continue\n",
    "                \n",
    "            # Only EPIC value is NaN/missing\n",
    "            if pd.isna(epic_value) and not pd.isna(secu_value):\n",
    "                epic_missing_count += 1\n",
    "                monthly_stats[month_name]['epic_missing_count'] += 1\n",
    "                monthly_stats[month_name]['total_compared'] += 1\n",
    "                variable_stats[var_key]['epic_missing_count'] += 1\n",
    "                variable_stats[var_key]['total_compared'] += 1\n",
    "                continue\n",
    "\n",
    "            # Compare values using the target type\n",
    "            if equivalent_values(epic_value, secu_value, target_type):\n",
    "                match_count += 1\n",
    "                monthly_stats[month_name]['match_count'] += 1\n",
    "                variable_stats[var_key]['match_count'] += 1\n",
    "            else:\n",
    "                mismatch_count += 1\n",
    "                monthly_stats[month_name]['mismatch_count'] += 1\n",
    "                variable_stats[var_key]['mismatch_count'] += 1\n",
    "                mismatched_results.append({\n",
    "                    'FID': fid,\n",
    "                    'SSR': ssr,\n",
    "                    'Month': month_name,\n",
    "                    'DATE': record_date,\n",
    "                    'EPIC Column': epic_col,\n",
    "                    'SecuTrial Column': secu_col,\n",
    "                    'EPIC Value': str(epic_value),\n",
    "                    'SecuTrial Value': str(secu_value),\n",
    "                    'EPIC Expected Type': column_types[epic_col]['epic_type'],\n",
    "                    'SecuTrial Expected Type': target_type,\n",
    "                    'EPIC Actual Type': type(epic_value).__name__,\n",
    "                    'SecuTrial Actual Type': type(secu_value).__name__\n",
    "                })\n",
    "            \n",
    "            monthly_stats[month_name]['total_compared'] += 1\n",
    "            variable_stats[var_key]['total_compared'] += 1\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_compared = match_count + mismatch_count + secu_missing_count + epic_missing_count\n",
    "    percentage_stats = {\n",
    "        \"Matching Variables (%)\": round((match_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in EPIC (%)\": round((epic_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Variables Missing in SecuTrial (%)\": round((secu_missing_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Mismatched Variables (%)\": round((mismatch_count / total_compared) * 100, 2) if total_compared else 0,\n",
    "        \"Total Comparisons\": total_compared,\n",
    "        \"Matches\": match_count,\n",
    "        \"EPIC Missing\": epic_missing_count,\n",
    "        \"SecuTrial Missing\": secu_missing_count,\n",
    "        \"Mismatches\": mismatch_count\n",
    "    }\n",
    "    \n",
    "    # Calculate monthly percentages\n",
    "    monthly_percentage_stats = {}\n",
    "    for month, stats in monthly_stats.items():\n",
    "        total = stats['total_compared']\n",
    "        if total > 0:\n",
    "            monthly_percentage_stats[month] = {\n",
    "                \"Matching Variables (%)\": round((stats['match_count'] / total) * 100, 2),\n",
    "                \"Variables Missing in EPIC (%)\": round((stats['epic_missing_count'] / total) * 100, 2),\n",
    "                \"Variables Missing in SecuTrial (%)\": round((stats['secu_missing_count'] / total) * 100, 2),\n",
    "                \"Mismatched Variables (%)\": round((stats['mismatch_count'] / total) * 100, 2),\n",
    "                \"Total Comparisons\": total,\n",
    "                \"Matches\": stats['match_count'],\n",
    "                \"EPIC Missing\": stats['epic_missing_count'],\n",
    "                \"SecuTrial Missing\": stats['secu_missing_count'],\n",
    "                \"Mismatches\": stats['mismatch_count']\n",
    "            }\n",
    "        else:\n",
    "            monthly_percentage_stats[month] = {\n",
    "                \"Matching Variables (%)\": 0,\n",
    "                \"Variables Missing in EPIC (%)\": 0,\n",
    "                \"Variables Missing in SecuTrial (%)\": 0,\n",
    "                \"Mismatched Variables (%)\": 0,\n",
    "                \"Total Comparisons\": 0,\n",
    "                \"Matches\": 0,\n",
    "                \"EPIC Missing\": 0,\n",
    "                \"SecuTrial Missing\": 0,\n",
    "                \"Mismatches\": 0\n",
    "            }\n",
    "    \n",
    "    # Calculate variable-level percentages\n",
    "    variable_percentage_stats = {}\n",
    "    for var_key, stats in variable_stats.items():\n",
    "        total = stats['total_compared']\n",
    "        if total > 0:\n",
    "            variable_percentage_stats[var_key] = {\n",
    "                \"Matching Values (%)\": round((stats['match_count'] / total) * 100, 2),\n",
    "                \"Values Missing in EPIC (%)\": round((stats['epic_missing_count'] / total) * 100, 2),\n",
    "                \"Values Missing in SecuTrial (%)\": round((stats['secu_missing_count'] / total) * 100, 2),\n",
    "                \"Mismatched Values (%)\": round((stats['mismatch_count'] / total) * 100, 2),\n",
    "                \"Total Comparisons\": total,\n",
    "                \"Matches\": stats['match_count'],\n",
    "                \"EPIC Missing\": stats['epic_missing_count'],\n",
    "                \"SecuTrial Missing\": stats['secu_missing_count'],\n",
    "                \"Mismatches\": stats['mismatch_count'],\n",
    "                \"EPIC Type\": stats['epic_type'],\n",
    "                \"SecuTrial Type\": stats['secu_type']\n",
    "            }\n",
    "        else:\n",
    "            variable_percentage_stats[var_key] = {\n",
    "                \"Matching Values (%)\": 0,\n",
    "                \"Values Missing in EPIC (%)\": 0,\n",
    "                \"Values Missing in SecuTrial (%)\": 0,\n",
    "                \"Mismatched Values (%)\": 0,\n",
    "                \"Total Comparisons\": 0,\n",
    "                \"Matches\": 0,\n",
    "                \"EPIC Missing\": 0,\n",
    "                \"SecuTrial Missing\": 0,\n",
    "                \"Mismatches\": 0,\n",
    "                \"EPIC Type\": stats['epic_type'],\n",
    "                \"SecuTrial Type\": stats['secu_type']\n",
    "            }\n",
    "\n",
    "    return pd.DataFrame(mismatched_results), percentage_stats, monthly_percentage_stats, variable_percentage_stats\n",
    "\n",
    "# Function to get top problematic variables\n",
    "def get_top_problematic_variables(variable_stats, sort_by='mismatch_percent', top_n=10):\n",
    "    \"\"\"\n",
    "    Identify the most problematic variables based on specified criteria\n",
    "    \n",
    "    Args:\n",
    "        variable_stats (dict): Dictionary containing variable-level statistics\n",
    "        sort_by (str): Criteria to sort by: 'mismatch_percent', 'missing_epic_percent', \n",
    "                       'missing_secuTrial_percent', or 'total_problems'\n",
    "        top_n (int): Number of variables to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Top problematic variables sorted by the specified criteria\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create a DataFrame from the variable stats\n",
    "    var_df = pd.DataFrame()\n",
    "    \n",
    "    for var_name, stats in variable_stats.items():\n",
    "        if stats['Total Comparisons'] > 0:  # Only include variables with actual comparisons\n",
    "            row = {\n",
    "                'Variable': var_name,\n",
    "                'Total Comparisons': stats['Total Comparisons'],\n",
    "                'Match Count': stats['Matches'],\n",
    "                'Match Percent': stats['Matching Values (%)'],\n",
    "                'Mismatch Count': stats['Mismatches'],\n",
    "                'Mismatch Percent': stats['Mismatched Values (%)'],\n",
    "                'EPIC Missing Count': stats['EPIC Missing'],\n",
    "                'EPIC Missing Percent': stats['Values Missing in EPIC (%)'],\n",
    "                'SecuTrial Missing Count': stats['SecuTrial Missing'],\n",
    "                'SecuTrial Missing Percent': stats['Values Missing in SecuTrial (%)'],\n",
    "                'EPIC Type': stats['EPIC Type'],\n",
    "                'SecuTrial Type': stats['SecuTrial Type'],\n",
    "                'Total Problems': stats['Mismatches'] + stats['EPIC Missing'] + stats['SecuTrial Missing'],\n",
    "                'Total Problem Percent': (100 - stats['Matching Values (%)'])\n",
    "            }\n",
    "            var_df = pd.concat([var_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "    # Sort based on criteria\n",
    "    if sort_by == 'mismatch_percent':\n",
    "        var_df = var_df.sort_values(by='Mismatch Percent', ascending=False)\n",
    "    elif sort_by == 'missing_epic_percent':\n",
    "        var_df = var_df.sort_values(by='EPIC Missing Percent', ascending=False)\n",
    "    elif sort_by == 'missing_secuTrial_percent':\n",
    "        var_df = var_df.sort_values(by='SecuTrial Missing Percent', ascending=False)\n",
    "    elif sort_by == 'total_problems':\n",
    "        var_df = var_df.sort_values(by='Total Problem Percent', ascending=False)\n",
    "    else:\n",
    "        var_df = var_df.sort_values(by='Total Problem Percent', ascending=False)\n",
    "    \n",
    "    return var_df.head(top_n)\n",
    "\n",
    "# Function to generate detailed report\n",
    "def generate_comparison_report(mismatched_results, overall_stats, monthly_stats, variable_stats):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive report from the comparison results\n",
    "    \n",
    "    Args:\n",
    "        mismatched_results (DataFrame): DataFrame with details of mismatched values\n",
    "        overall_stats (dict): Dictionary with overall statistics\n",
    "        monthly_stats (dict): Dictionary with monthly breakdown of statistics\n",
    "        variable_stats (dict): Dictionary with variable-level statistics\n",
    "        \n",
    "    Returns:\n",
    "        str: Markdown formatted report\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from io import StringIO\n",
    "    \n",
    "    report = StringIO()\n",
    "    \n",
    "    # Overall Summary\n",
    "    report.write(\"# EPIC-SecuTrial Data Comparison Summary\\n\\n\")\n",
    "    report.write(\"## Overall Statistics\\n\\n\")\n",
    "    report.write(f\"* Total Comparisons: {overall_stats['Total Comparisons']}\\n\")\n",
    "    report.write(f\"* Matching Variables: {overall_stats['Matches']} ({overall_stats['Matching Variables (%)']}%)\\n\")\n",
    "    report.write(f\"* Mismatched Variables: {overall_stats['Mismatches']} ({overall_stats['Mismatched Variables (%)']}%)\\n\")\n",
    "    report.write(f\"* Variables Missing in EPIC: {overall_stats['EPIC Missing']} ({overall_stats['Variables Missing in EPIC (%)']}%)\\n\")\n",
    "    report.write(f\"* Variables Missing in SecuTrial: {overall_stats['SecuTrial Missing']} ({overall_stats['Variables Missing in SecuTrial (%)']}%)\\n\\n\")\n",
    "    \n",
    "    # Monthly Breakdown\n",
    "    report.write(\"## Monthly Statistics\\n\\n\")\n",
    "    monthly_df = pd.DataFrame(columns=['Month', 'Total Comparisons', 'Matching (%)', 'Mismatched (%)', \n",
    "                                       'EPIC Missing (%)', 'SecuTrial Missing (%)'])\n",
    "    \n",
    "    for month, stats in monthly_stats.items():\n",
    "        monthly_df = pd.concat([monthly_df, pd.DataFrame([{\n",
    "            'Month': month,\n",
    "            'Total Comparisons': stats['Total Comparisons'],\n",
    "            'Matching (%)': stats['Matching Variables (%)'],\n",
    "            'Mismatched (%)': stats['Mismatched Variables (%)'],\n",
    "            'EPIC Missing (%)': stats['Variables Missing in EPIC (%)'],\n",
    "            'SecuTrial Missing (%)': stats['Variables Missing in SecuTrial (%)']\n",
    "        }])], ignore_index=True)\n",
    "    \n",
    "    report.write(monthly_df.to_markdown(index=False))\n",
    "    report.write(\"\\n\\n\")\n",
    "    \n",
    "    # Top Problematic Variables\n",
    "    report.write(\"## Top 10 Problematic Variables\\n\\n\")\n",
    "    top_vars = get_top_problematic_variables(variable_stats, sort_by='total_problems', top_n=10)\n",
    "    report.write(top_vars[['Variable', 'Total Comparisons', 'Match Percent', 'Mismatch Percent', \n",
    "                           'EPIC Missing Percent', 'SecuTrial Missing Percent', 'EPIC Type', 'SecuTrial Type']]\n",
    "                .to_markdown(index=False))\n",
    "    report.write(\"\\n\\n\")\n",
    "    \n",
    "    # Variables with Type Mismatches\n",
    "    report.write(\"## Variables with Type Mismatches\\n\\n\")\n",
    "    type_mismatches = []\n",
    "    for var_name, stats in variable_stats.items():\n",
    "        if stats['EPIC Type'] != stats['SecuTrial Type']:\n",
    "            type_mismatches.append({\n",
    "                'Variable': var_name,\n",
    "                'EPIC Type': stats['EPIC Type'],\n",
    "                'SecuTrial Type': stats['SecuTrial Type'],\n",
    "                'Mismatch Percent': stats['Mismatched Values (%)']\n",
    "            })\n",
    "    \n",
    "    if type_mismatches:\n",
    "        type_mismatch_df = pd.DataFrame(type_mismatches)\n",
    "        report.write(type_mismatch_df.sort_values(by='Mismatch Percent', ascending=False).to_markdown(index=False))\n",
    "    else:\n",
    "        report.write(\"No type mismatches found.\\n\")\n",
    "    \n",
    "    return report.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comparison application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DATE column to EPIC dataframe\n",
    "df_EPIC_all_2['DATE'] = df_EPIC_all_2['enct.arrival_date'] \n",
    "\n",
    "# Add DATE column to secuTrial dataframe\n",
    "df_secuTrial_w_REVAS_2['DATE'] = df_secuTrial_w_REVAS_2['Arrival at hospital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now proceed with comparison using the aligned data\n",
    "#mismatched_results, comparison_stats, monthly_percentage_stats = compare_epic_secuTrial(df_EPIC_all_2, df_secuTrial_w_REVAS_2, df_mapping, value_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now proceed with comparison using the aligned data\n",
    "mismatched_results, comparison_stats, monthly_percentage_stats, variable_stats = compare_epic_secuTrial(df_EPIC_all_2, df_secuTrial_w_REVAS_2, df_mapping, value_mappings)\n",
    "\n",
    "# Optionally generate a comprehensive report\n",
    "report = generate_comparison_report(mismatched_results, comparison_stats, monthly_percentage_stats, variable_stats)\n",
    "print(report)  # Or save to a file with: with open('comparison_report.md', 'w') as f: f.write(report)\n",
    "\n",
    "# Export variable statistics to Excel\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for variable statistics\n",
    "variable_df = pd.DataFrame()\n",
    "for var_name, stats in variable_stats.items():\n",
    "    row = {\n",
    "        'Variable': var_name,\n",
    "        'Total Comparisons': stats['Total Comparisons'],\n",
    "        'Matches': stats['Matches'],\n",
    "        'Match Percent': stats['Matching Values (%)'],\n",
    "        'Mismatches': stats['Mismatches'],\n",
    "        'Mismatch Percent': stats['Mismatched Values (%)'],\n",
    "        'EPIC Missing': stats['EPIC Missing'],\n",
    "        'EPIC Missing Percent': stats['Values Missing in EPIC (%)'],\n",
    "        'SecuTrial Missing': stats['SecuTrial Missing'],\n",
    "        'SecuTrial Missing Percent': stats['Values Missing in SecuTrial (%)'],\n",
    "        'EPIC Type': stats['EPIC Type'],\n",
    "        'SecuTrial Type': stats['SecuTrial Type']\n",
    "    }\n",
    "    variable_df = pd.concat([variable_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Sort by highest mismatch percentage\n",
    "variable_df = variable_df.sort_values(by='Mismatch Percent', ascending=False)\n",
    "\n",
    "# Export to Excel\n",
    "variable_df.to_excel('variable_statistics.xlsx', index=False)\n",
    "\n",
    "# You can also export the mismatched results for detailed examination\n",
    "mismatched_results.to_excel('mismatched_values.xlsx', index=False)\n",
    "\n",
    "# Export monthly statistics to Excel\n",
    "monthly_df = pd.DataFrame()\n",
    "for month, stats in monthly_percentage_stats.items():\n",
    "    row = {\n",
    "        'Month': month,\n",
    "        'Total Comparisons': stats['Total Comparisons'],\n",
    "        'Matches': stats['Matches'],\n",
    "        'Match Percent': stats['Matching Variables (%)'],\n",
    "        'Mismatches': stats['Mismatches'],\n",
    "        'Mismatch Percent': stats['Mismatched Variables (%)'],\n",
    "        'EPIC Missing': stats['EPIC Missing'],\n",
    "        'EPIC Missing Percent': stats['Variables Missing in EPIC (%)'],\n",
    "        'SecuTrial Missing': stats['SecuTrial Missing'], \n",
    "        'SecuTrial Missing Percent': stats['Variables Missing in SecuTrial (%)']\n",
    "    }\n",
    "    monthly_df = pd.concat([monthly_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Export monthly statistics\n",
    "with pd.ExcelWriter('comparison_statistics.xlsx') as writer:\n",
    "    variable_df.to_excel(writer, sheet_name='Variable Statistics', index=False)\n",
    "    monthly_df.to_excel(writer, sheet_name='Monthly Statistics', index=False)\n",
    "    pd.DataFrame([comparison_stats]).to_excel(writer, sheet_name='Overall Statistics', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert comparison statistics to a DataFrame and display\n",
    "comparison_stats_df = pd.DataFrame([comparison_stats])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the monthly statistics to Excel\n",
    "output_dir = base_dir / 'EPIC-export-validation/validation-files'\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "monthly_stats_path = output_dir / f\"monthly_validation_stats_{timestamp}.xlsx\"\n",
    "\n",
    "# Convert monthly stats to DataFrames\n",
    "monthly_stats_df = pd.DataFrame.from_dict(monthly_percentage_stats, orient='index')\n",
    "\n",
    "# Create a styled Excel writer\n",
    "with pd.ExcelWriter(monthly_stats_path, engine='openpyxl') as writer:\n",
    "    # Write monthly stats\n",
    "    monthly_stats_df.to_excel(writer, sheet_name=\"Monthly_Stats\")\n",
    "    \n",
    "    # Write overall stats\n",
    "    pd.DataFrame([comparison_stats]).to_excel(writer, sheet_name=\"Overall_Stats\", index=False)\n",
    "\n",
    "print(f\"Monthly statistics saved to: {monthly_stats_path}\")\n",
    "\n",
    "# Print summary of monthly stats\n",
    "print(\"\\nMonthly Statistics Summary:\")\n",
    "print(\"---------------------------\")\n",
    "for month, stats in monthly_percentage_stats.items():\n",
    "    print(f\"\\n{month}:\")\n",
    "    print(f\"  Matches: {stats['Matches']} ({stats['Matching Variables (%)']}%)\")\n",
    "    print(f\"  Mismatches: {stats['Mismatches']} ({stats['Mismatched Variables (%)']}%)\")\n",
    "    print(f\"  Total comparisons: {stats['Total Comparisons']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismatch report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_mismatched_data(differences_df, epic_df):\n",
    "    \"\"\"\n",
    "    Restructures the mismatched data so that each row represents a single (FID, SSR),\n",
    "    and each discrepancy appears in separate columns.\n",
    "\n",
    "    Args:\n",
    "        differences_df (DataFrame): DataFrame containing mismatched values.\n",
    "        epic_df (DataFrame): The original EPIC DataFrame to determine column order.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A structured DataFrame where mismatches are arranged in a single row per patient.\n",
    "    \"\"\"\n",
    "    # Standardize column names to prevent mismatches\n",
    "    differences_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "    required_columns = [\"FID\", \"SSR\", \"EPIC Column\", \"SecuTrial Column\", \"EPIC Value\", \"SecuTrial Value\"]\n",
    "    missing_columns = [col for col in required_columns if col not in differences_df.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns in differences_df: {missing_columns}\")\n",
    "\n",
    "    # Resolve duplicates by taking the first occurrence\n",
    "    duplicate_check = differences_df.duplicated(subset=[\"FID\", \"SSR\", \"EPIC Column\"], keep=False)\n",
    "    if duplicate_check.any():\n",
    "        print(f\"Warning: {duplicate_check.sum()} duplicate rows found. Resolving by taking the first occurrence.\")\n",
    "\n",
    "    differences_df = differences_df.groupby([\"FID\", \"SSR\", \"EPIC Column\"], as_index=False).first()\n",
    "\n",
    "    # Pivot the table to make each discrepancy a separate column\n",
    "    pivoted_df = differences_df.pivot(index=[\"FID\", \"SSR\"], \n",
    "                                      columns=\"EPIC Column\", \n",
    "                                      values=[\"SecuTrial Value\", \"EPIC Value\"])\n",
    "\n",
    "    # Flatten multi-level column names\n",
    "    pivoted_df.columns = [f\"{col[1]}_st\" if col[0] == \"SecuTrial Value\" else f\"{col[1]}_ep\" \n",
    "                          for col in pivoted_df.columns]\n",
    "\n",
    "    # Reset index to include FID and SSR as columns\n",
    "    pivoted_df.reset_index(inplace=True)\n",
    "\n",
    "    # Debug: Print column names after pivot\n",
    "    #print(\"Columns after pivot:\", pivoted_df.columns)\n",
    "\n",
    "    # Ensure column order follows the order in the original EPIC DataFrame\n",
    "    column_order = [\"FID\", \"SSR\"]\n",
    "\n",
    "    # Extract base column names from epic_df (without prefix/suffix)\n",
    "    base_columns = [col for col in epic_df.columns if not col.startswith((\"FID\", \"SSR\"))]\n",
    "\n",
    "    # Ensure `_st` (SecuTrial) columns appear first, then `_ep` (EPIC) columns\n",
    "    for col in base_columns:\n",
    "        if f\"{col}_st\" in pivoted_df.columns:\n",
    "            column_order.append(f\"{col}_st\")\n",
    "        if f\"{col}_ep\" in pivoted_df.columns:\n",
    "            column_order.append(f\"{col}_ep\")\n",
    "\n",
    "    # Debug: Check if any expected columns are missing\n",
    "    missing_expected_columns = [col for col in column_order if col not in pivoted_df.columns]\n",
    "    if missing_expected_columns:\n",
    "        print(f\"⚠️ Warning: Some expected columns are missing after pivot: {missing_expected_columns}\")\n",
    "\n",
    "    # Select only available columns and reorder\n",
    "    column_order = [col for col in column_order if col in pivoted_df.columns]\n",
    "    pivoted_df = pivoted_df[column_order]\n",
    "\n",
    "    # Fill NaN values with an empty string for better readability\n",
    "    pivoted_df.fillna(\"\", inplace=True)\n",
    "\n",
    "    return pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_df = restructure_mismatched_data(mismatched_results, df_EPIC_all_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new EPIC and sT dataframe as Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory and ensure it exists\n",
    "output_dir = base_dir / 'EPIC-export-validation/validation-files'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate timestamped file name and path\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file_path = output_dir / f\"df_EPIC_all_{timestamp}.xlsx\"\n",
    "\n",
    "# Save the DataFrame\n",
    "try:\n",
    "    df_EPIC_all.to_excel(output_file_path, index=False)\n",
    "    print(f\"File saved successfully at: {output_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output file path\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file_path = output_dir / f\"df_secuTrial_w_REVAS_{timestamp}.xlsx\"\n",
    "\n",
    "# Save the DataFrame\n",
    "try:\n",
    "    df_secuTrial_w_REVAS.to_excel(output_file_path, index=False)\n",
    "    print(f\"File saved successfully at: {output_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output file path\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file_path = output_dir / f\"report_mismatched_values_{timestamp}.xlsx\"\n",
    "\n",
    "# Save the DataFrame\n",
    "try:\n",
    "    restructured_df.to_excel(output_file_path, index=False)\n",
    "    print(f\"File saved successfully at: {output_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
